{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48f137ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (2.1.3)\n",
      "Requirement already satisfied: rich in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (0.1.0)\n",
      "Requirement already satisfied: h5py in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (3.14.0)\n",
      "Requirement already satisfied: optree in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (0.16.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from keras) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from rich->keras) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\anurag rawat\\anaconda3\\envs\\arnav\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30feda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9221cb0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Product_Category', 'Product_Price', 'Order_Quantity', 'Return_Reason', 'Return_Status', 'User_Age', 'User_Gender', 'User_Location', 'Payment_Method', 'Shipping_Method']\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv(\"newcleaneddata.csv\")\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "480e7ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Product_Price', axis=1)\n",
    "data = data.drop('Order_Quantity', axis=1)\n",
    "data = data.drop('User_Location', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "014a1c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "##encode categorical value\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode User_Gender\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['User_Gender'] = label_encoder_gender.fit_transform(data['User_Gender'])\n",
    "\n",
    "# Encode Return_Status (Target)\n",
    "label_encoder_status = LabelEncoder()\n",
    "data['Return_Status'] = label_encoder_status.fit_transform(data['Return_Status'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed45856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('gender_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder_gender, f)\n",
    "\n",
    "with open('status_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder_status, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2b852009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "payment_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "payment_encoded = payment_encoder.fit_transform(data[['Payment_Method']])\n",
    "payment_encoded_df = pd.DataFrame(payment_encoded, columns=payment_encoder.get_feature_names_out(['Payment_Method']))\n",
    "with open('payment_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(payment_encoder, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37858d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data.drop('Payment_Method', axis=1), payment_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "afb5c519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Return_Reason_Changed mind  Return_Reason_Defective  \\\n",
      "0                         1.0                      0.0   \n",
      "1                         0.0                      0.0   \n",
      "2                         0.0                      0.0   \n",
      "3                         0.0                      0.0   \n",
      "4                         0.0                      0.0   \n",
      "\n",
      "   Return_Reason_Not as described  Return_Reason_Wrong item  Return_Reason_nan  \n",
      "0                             0.0                       0.0                0.0  \n",
      "1                             0.0                       1.0                0.0  \n",
      "2                             0.0                       0.0                1.0  \n",
      "3                             0.0                       0.0                1.0  \n",
      "4                             0.0                       0.0                1.0  \n"
     ]
    }
   ],
   "source": [
    "return_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Fit-transform 'Return_Reason'\n",
    "return_encoded = return_encoder.fit_transform(data[['Return_Reason']])\n",
    "\n",
    "# Create a DataFrame with appropriate column names\n",
    "return_encoded_df = pd.DataFrame(return_encoded, columns=return_encoder.get_feature_names_out(['Return_Reason']))\n",
    "\n",
    "# Reset index for safe merging later (if needed)\n",
    "return_encoded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Preview the result\n",
    "print(return_encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b30da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data.drop('Return_Reason', axis=1),return_encoded_df ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f00d8f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Shipping_Method_Express  Shipping_Method_Next-Day  Shipping_Method_Standard\n",
      "0                      0.0                       1.0                       0.0\n",
      "1                      1.0                       0.0                       0.0\n",
      "2                      0.0                       1.0                       0.0\n",
      "3                      0.0                       1.0                       0.0\n",
      "4                      0.0                       0.0                       1.0\n"
     ]
    }
   ],
   "source": [
    "shipping_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Fit and transform the 'Shipping_Method' column\n",
    "shipping_encoded = shipping_encoder.fit_transform(data[['Shipping_Method']])\n",
    "\n",
    "# Create DataFrame with proper column names\n",
    "shipping_encoded_df = pd.DataFrame(\n",
    "    shipping_encoded,\n",
    "    columns=shipping_encoder.get_feature_names_out(['Shipping_Method'])\n",
    ")\n",
    "\n",
    "# Reset index (optional, for future concatenation)\n",
    "shipping_encoded_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display result\n",
    "print(shipping_encoded_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "95e70034",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data.drop('Shipping_Method', axis=1),shipping_encoded_df ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ead25534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    4\n",
      "3    4\n",
      "4    0\n",
      "Name: Product_Category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "product_label_encoder = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding to 'Product_Category'\n",
    "data['Product_Category'] = product_label_encoder.fit_transform(data['Product_Category'])\n",
    "\n",
    "# (Optional) Save the encoder for future predictions\n",
    "import pickle\n",
    "with open('product_label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(product_label_encoder, f)\n",
    "\n",
    "# Preview\n",
    "print(data['Product_Category'].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "21061b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save LabelEncoder for Product_Category (if used)\n",
    "with open('product_label_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(product_label_encoder, file)\n",
    "\n",
    "# Save OneHotEncoders\n",
    "with open('shipping_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(shipping_encoder, file)\n",
    "\n",
    "with open('return_reason_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(return_encoder, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44ea2446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Product_Category', 'Return_Status', 'User_Age', 'User_Gender',\n",
      "       'Payment_Method_Credit Card', 'Payment_Method_Debit Card',\n",
      "       'Payment_Method_Gift Card', 'Payment_Method_PayPal',\n",
      "       'Return_Reason_Changed mind', 'Return_Reason_Defective',\n",
      "       'Return_Reason_Not as described', 'Return_Reason_Wrong item',\n",
      "       'Return_Reason_nan', 'Shipping_Method_Express',\n",
      "       'Shipping_Method_Next-Day', 'Shipping_Method_Standard'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f4dbdc6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Product_Category', 'Return_Status', 'User_Age', 'User_Gender',\n",
      "       'Payment_Method_Credit Card', 'Payment_Method_Debit Card',\n",
      "       'Payment_Method_Gift Card', 'Payment_Method_PayPal',\n",
      "       'Return_Reason_Changed mind', 'Return_Reason_Defective',\n",
      "       'Return_Reason_Not as described', 'Return_Reason_Wrong item',\n",
      "       'Return_Reason_nan', 'Shipping_Method_Express',\n",
      "       'Shipping_Method_Next-Day', 'Shipping_Method_Standard'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4de08996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Product_Category', 'Return_Status', 'User_Age', 'User_Gender',\n",
      "       'Payment_Method_Credit Card', 'Payment_Method_Debit Card',\n",
      "       'Payment_Method_Gift Card', 'Payment_Method_PayPal',\n",
      "       'Return_Reason_Changed mind', 'Return_Reason_Defective',\n",
      "       'Return_Reason_Not as described', 'Return_Reason_Wrong item',\n",
      "       'Return_Reason_nan', 'Shipping_Method_Express',\n",
      "       'Shipping_Method_Next-Day', 'Shipping_Method_Standard'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5a5e1723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (8000, 15)\n",
      "X_test shape: (2000, 15)\n",
      "y_train shape: (8000,)\n",
      "y_test shape: (2000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# 1. Separate independent features (X) and the target (y)\n",
    "X = data.drop('Return_Status', axis=1)\n",
    "y = data['Return_Status']\n",
    "\n",
    "# 2. Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# 3. Apply scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 4. Save the scaler for future use\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n",
    "\n",
    "# âœ… Optional: Print shapes for verification\n",
    "print(\"X_train shape:\", X_train_scaled.shape)\n",
    "print(\"X_test shape:\", X_test_scaled.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0766d780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ANURAG RAWAT\\anaconda3\\envs\\arnav\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # For binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6ca9c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "# Set up the TensorBoard log directory with proper datetime format\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Create the TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Optional: Add early stopping to avoid overfitting\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1cfa540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set up early stooping\n",
    "early_stopping_callback=EarlyStopping(monitor='cal_loss',patience=5,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b449dd",
   "metadata": {},
   "source": [
    "#train the model\n",
    "history=model.fit(\n",
    "    X_train,y_train,validation_data=(X_test,y_test),epochs=100,\n",
    "    callbacks=(tensor_flow_callback,early_stopping_callback)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "aebfe859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('return_ann_model_v1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "de1156c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kill' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kill 25432\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "849493ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 6000), started 22:06:09 ago. (Use '!kill 6000' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d0d2d3e78c49c387\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d0d2d3e78c49c387\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit --port 6006\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "afdcc2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f09fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arnav",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
